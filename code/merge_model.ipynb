{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Merge the models of ship head classifiation netwrok and ship loalization netwrok into one moldel used for detection.\n",
    "Thi file is opened using Anaconda.\n",
    "\n",
    "In this file, we provide two means to get models. \n",
    "\n",
    "The first means is in the first three cells. The code in the first three cells is used to generate the model for iterative regression and then classification.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*******************\n",
      "net\n",
      "blobs ['conv1_1', 'conv1_2', 'conv1_3', 'conv2_1', 'conv2_2', 'conv3', 'conv4', 'conv5', 'fc6', 'bbox_pred', 'fc7', 'bbox_pred_2', 'fc8', 'clssify']\n",
      "params ['conv1_1', 'conv1_2', 'conv1_3', 'conv2_1', 'conv2_2', 'conv3', 'conv4', 'conv5', 'fc6', 'bbox_pred', 'fc7', 'bbox_pred_2', 'fc8', 'clssify']\n",
      "*******************\n",
      "net2\n",
      "blobs ['conv1_1', 'conv1_2', 'conv1_3', 'conv2_1', 'conv2_2', 'conv3', 'conv4', 'conv5', 'ip6', 'bbox_pred', 'clssify']\n",
      "params ['conv1_1', 'conv1_2', 'conv1_3', 'conv2_1', 'conv2_2', 'conv3', 'conv4', 'conv5', 'ip6', 'bbox_pred', 'clssify']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import sys, os\n",
    "ROOT_DIR = os.getcwd()\n",
    "\n",
    "# this file should be run from {caffe_root}/examples (otherwise change this line)\n",
    "sys.path.insert(0, ROOT_DIR + '/caffe/python')\n",
    "\n",
    "import caffe\n",
    "sys.path.insert(0, ROOT_DIR + '/lib')\n",
    "\n",
    "\n",
    "caffe.set_mode_gpu()\n",
    "caffe.set_device(0)\n",
    "\n",
    "# the prototxt that define the destination model \n",
    "model_def = ROOT_DIR + '/test_cascade_2.prototxt'\n",
    "net       = caffe.Net(model_def,caffe.TEST) \n",
    "print ('*******************')\n",
    "print ('net')\n",
    "print ('blobs {}\\nparams {}'.format(net.params.keys(), net.params.keys()))\n",
    "\n",
    "\n",
    "\n",
    "# the prototxt that define the source model \n",
    "model_def2     = ROOT_DIR + '/shipbody/train_ship_cla_reg.prototxt'\n",
    "model_weights2 = ROOT_DIR + '/shipbody/ship_2_iter_100000.caffemodel'\n",
    "net2           = caffe.Net(model_def2, model_weights2, caffe.TRAIN) \n",
    "print ('*******************')\n",
    "print ('net2')\n",
    "print ('blobs {}\\nparams {}'.format(net2.params.keys(), net2.params.keys()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# transfer the weights and biase from the source model to the destination model\n",
    "net.params['conv1_1'][0].data[...] = net2.params['conv1_1'][0].data\n",
    "net.params['conv1_1'][1].data[...] = net2.params['conv1_1'][1].data\n",
    "net.params['conv1_2'][0].data[...] = net2.params['conv1_2'][0].data\n",
    "net.params['conv1_2'][1].data[...] = net2.params['conv1_2'][1].data\n",
    "net.params['conv1_3'][0].data[...] = net2.params['conv1_3'][0].data\n",
    "net.params['conv1_3'][1].data[...] = net2.params['conv1_3'][1].data\n",
    "\n",
    "net.params['conv2_1'][0].data[...] = net2.params['conv2_1'][0].data\n",
    "net.params['conv2_1'][1].data[...] = net2.params['conv2_1'][1].data\n",
    "net.params['conv2_2'][0].data[...] = net2.params['conv2_2'][0].data\n",
    "net.params['conv2_2'][1].data[...] = net2.params['conv2_2'][1].data\n",
    "\n",
    "net.params['conv3'][0].data[...] = net2.params['conv3'][0].data\n",
    "net.params['conv3'][1].data[...] = net2.params['conv3'][1].data\n",
    "\n",
    "net.params['conv4'][0].data[...] = net2.params['conv4'][0].data\n",
    "net.params['conv4'][1].data[...] = net2.params['conv4'][1].data\n",
    "\n",
    "net.params['conv5'][0].data[...] = net2.params['conv5'][0].data\n",
    "net.params['conv5'][1].data[...] = net2.params['conv5'][1].data\n",
    "\n",
    "\n",
    "net.params['fc6'][0].data[...] = net2.params['ip6'][0].data\n",
    "net.params['fc6'][1].data[...] = net2.params['ip6'][1].data\n",
    "\n",
    "net.params['fc7'][0].data[...] = net2.params['ip6'][0].data\n",
    "net.params['fc7'][1].data[...] = net2.params['ip6'][1].data\n",
    "\n",
    "net.params['fc8'][0].data[...] = net2.params['ip6'][0].data\n",
    "net.params['fc8'][1].data[...] = net2.params['ip6'][1].data\n",
    "\n",
    "net.params['bbox_pred'][0].data[...] = net2.params['bbox_pred'][0].data\n",
    "net.params['bbox_pred'][1].data[...] = net2.params['bbox_pred'][1].data\n",
    "\n",
    "net.params['bbox_pred_2'][0].data[...] = net2.params['bbox_pred'][0].data\n",
    "net.params['bbox_pred_2'][1].data[...] = net2.params['bbox_pred'][1].data\n",
    "\n",
    "net.params['clssify'][0].data[...] = net2.params['clssify'][0].data\n",
    "net.params['clssify'][1].data[...] = net2.params['clssify'][1].data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "net.save(ROOT_DIR + '/demo_cascade_2.caffemodel')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The second means is in the following three cells. The code in these three cells is used to generate the model for both ship head classification and ship localization simultaneously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*******************\n",
      "net\n",
      "blobs ['conv1_h', 'conv2_h', 'conv3_h', 'conv4_h', 'conv1_1', 'conv1_2', 'conv1_3', 'conv2_1', 'conv2_2', 'conv3', 'conv4', 'conv5', 'fc6', 'bbox_pred', 'fc7', 'bbox_pred_2', 'fc8', 'clssify']\n",
      "params ['conv1_h', 'conv2_h', 'conv3_h', 'conv4_h', 'conv1_1', 'conv1_2', 'conv1_3', 'conv2_1', 'conv2_2', 'conv3', 'conv4', 'conv5', 'fc6', 'bbox_pred', 'fc7', 'bbox_pred_2', 'fc8', 'clssify']\n",
      "*******************\n",
      "net1\n",
      "blobs ['conv1', 'conv2', 'conv3', 'conv4']\n",
      "params ['conv1', 'conv2', 'conv3', 'conv4']\n",
      "*******************\n",
      "net2\n",
      "blobs ['conv1_1', 'conv1_2', 'conv1_3', 'conv2_1', 'conv2_2', 'conv3', 'conv4', 'conv5', 'ip6', 'bbox_pred', 'clssify']\n",
      "params ['conv1_1', 'conv1_2', 'conv1_3', 'conv2_1', 'conv2_2', 'conv3', 'conv4', 'conv5', 'ip6', 'bbox_pred', 'clssify']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import sys, os\n",
    "ROOT_DIR = os.getcwd()\n",
    "\n",
    "# this file should be run from {caffe_root}/examples (otherwise change this line)\n",
    "sys.path.insert(0,ROOT_DIR + '/caffe/python')\n",
    "import caffe\n",
    "sys.path.insert(0,ROOT_DIR + '/lib')\n",
    "\n",
    "caffe.set_mode_gpu()\n",
    "caffe.set_device(0)\n",
    "\n",
    "# the prototxt that define the destination model \n",
    "model_def   = ROOT_DIR + '/test.prototxt'\n",
    "net         = caffe.Net(model_def,caffe.TEST) \n",
    "print ('*******************')\n",
    "print ('net')\n",
    "print ('blobs {}\\nparams {}'.format(net.params.keys(), net.params.keys()))\n",
    "\n",
    "# the prototxt that define the source model 1\n",
    "model_def1     = ROOT_DIR + '/test_shiphead.prototxt'\n",
    "model_weights1 = ROOT_DIR + '/shiphead/shiphead_2_iter_30000.caffemodel'\n",
    "net1           = caffe.Net(model_def1, model_weights1,caffe.TEST) \n",
    "print ('*******************')\n",
    "print ('net1')\n",
    "print ('blobs {}\\nparams {}'.format(net1.params.keys(), net1.params.keys()))\n",
    "\n",
    "# the prototxt that define the source model 2\n",
    "model_def2     = ROOT_DIR + '/shipbody/train_ship_cla_reg.prototxt'\n",
    "model_weights2 = ROOT_DIR + '/shipbody/ship_2_iter_100000.caffemodel'\n",
    "net2           = caffe.Net(model_def2,model_weights2,caffe.TEST) \n",
    "print ('*******************')\n",
    "print ('net2')\n",
    "print ('blobs {}\\nparams {}'.format(net2.params.keys(), net2.params.keys()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'bbox_pred_2'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-a8b664e01625>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'bbox_pred'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'bbox_pred'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'bbox_pred_2'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'bbox_pred_2'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'bbox_pred_2'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'bbox_pred_2'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'bbox_pred_2'"
     ]
    }
   ],
   "source": [
    "# transfer the weights and biase from the source models to the destination model\n",
    "net.params['conv1_h'][0].data[...] = net1.params['conv1'][0].data\n",
    "net.params['conv1_h'][1].data[...] = net1.params['conv1'][1].data\n",
    "net.params['conv2_h'][0].data[...] = net1.params['conv2'][0].data\n",
    "net.params['conv2_h'][1].data[...] = net1.params['conv2'][1].data\n",
    "net.params['conv3_h'][0].data[...] = net1.params['conv3'][0].data\n",
    "net.params['conv3_h'][1].data[...] = net1.params['conv3'][1].data\n",
    "net.params['conv4_h'][0].data[...] = net1.params['conv4'][0].data\n",
    "net.params['conv4_h'][1].data[...] = net1.params['conv4'][1].data\n",
    "\n",
    "\n",
    "net.params['conv1_1'][0].data[...] = net2.params['conv1_1'][0].data\n",
    "net.params['conv1_1'][1].data[...] = net2.params['conv1_1'][1].data\n",
    "net.params['conv1_2'][0].data[...] = net2.params['conv1_2'][0].data\n",
    "net.params['conv1_2'][1].data[...] = net2.params['conv1_2'][1].data\n",
    "net.params['conv1_3'][0].data[...] = net2.params['conv1_3'][0].data\n",
    "net.params['conv1_3'][1].data[...] = net2.params['conv1_3'][1].data\n",
    "\n",
    "net.params['conv2_1'][0].data[...] = net2.params['conv2_1'][0].data\n",
    "net.params['conv2_1'][1].data[...] = net2.params['conv2_1'][1].data\n",
    "net.params['conv2_2'][0].data[...] = net2.params['conv2_2'][0].data\n",
    "net.params['conv2_2'][1].data[...] = net2.params['conv2_2'][1].data\n",
    "\n",
    "net.params['conv3'][0].data[...] = net2.params['conv3'][0].data\n",
    "net.params['conv3'][1].data[...] = net2.params['conv3'][1].data\n",
    "\n",
    "net.params['conv4'][0].data[...] = net2.params['conv4'][0].data\n",
    "net.params['conv4'][1].data[...] = net2.params['conv4'][1].data\n",
    "\n",
    "net.params['conv5'][0].data[...] = net2.params['conv5'][0].data\n",
    "net.params['conv5'][1].data[...] = net2.params['conv5'][1].data\n",
    "\n",
    "\n",
    "net.params['fc6'][0].data[...] = net2.params['ip6'][0].data\n",
    "net.params['fc6'][1].data[...] = net2.params['ip6'][1].data\n",
    "\n",
    "net.params['fc7'][0].data[...] = net2.params['ip6'][0].data\n",
    "net.params['fc7'][1].data[...] = net2.params['ip6'][1].data\n",
    "\n",
    "net.params['fc8'][0].data[...] = net2.params['ip6'][0].data\n",
    "net.params['fc8'][1].data[...] = net2.params['ip6'][1].data\n",
    "\n",
    "net.params['bbox_pred'][0].data[...] = net2.params['bbox_pred'][0].data\n",
    "net.params['bbox_pred'][1].data[...] = net2.params['bbox_pred'][1].data\n",
    "\n",
    "net.params['bbox_pred_2'][0].data[...] = net2.params['bbox_pred'][0].data\n",
    "net.params['bbox_pred_2'][1].data[...] = net2.params['bbox_pred'][1].data\n",
    "\n",
    "net.params['clssify'][0].data[...] = net2.params['clssify'][0].data\n",
    "net.params['clssify'][1].data[...] = net2.params['clssify'][1].data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "net.save(ROOT_DIR + '/demo.caffemodel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "description": "Instant recognition with a pre-trained model and a tour of the net interface for visualizing features and parameters layer-by-layer.",
  "example_name": "Image Classification and Filter Visualization",
  "include_in_docs": true,
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  },
  "priority": 1
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
